{"version":{"pluginId":"default","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"tutorialSidebar":[{"type":"link","href":"/docs/intro","label":"Introduction to Physical AI & Humanoid Robotics","docId":"intro","unlisted":false},{"type":"link","href":"/docs/getting-started","label":"Getting Started","docId":"getting-started","unlisted":false},{"type":"category","label":"Module 1: The Robotic Nervous System (ROS 2)","items":[{"type":"link","href":"/docs/module-1-the-robotic-nervous-system/lesson-1-introduction-to-ros2","label":"Lesson 1 - Introduction to ROS 2","docId":"module-1-the-robotic-nervous-system/lesson-1-introduction-to-ros2","unlisted":false},{"type":"link","href":"/docs/module-1-the-robotic-nervous-system/lesson-2-nodes-topics-services","label":"Lesson 2 - ROS 2 Nodes, Topics, and Services","docId":"module-1-the-robotic-nervous-system/lesson-2-nodes-topics-services","unlisted":false},{"type":"link","href":"/docs/module-1-the-robotic-nervous-system/lesson-3-bridging-python-agents","label":"Lesson 3 - Bridging Python Agents to ROS Controllers using rclpy","docId":"module-1-the-robotic-nervous-system/lesson-3-bridging-python-agents","unlisted":false},{"type":"link","href":"/docs/module-1-the-robotic-nervous-system/lesson-4-understanding-urdf","label":"Lesson 4 - Understanding URDF (Unified Robot Description Format) for Humanoids","docId":"module-1-the-robotic-nervous-system/lesson-4-understanding-urdf","unlisted":false}],"collapsed":true,"collapsible":true,"href":"/docs/module-1-the-robotic-nervous-system/intro"},{"type":"category","label":"Module 2: The Digital Twin (Gazebo & Unity)","items":[{"type":"link","href":"/docs/module-2-the-digital-twin/lesson-1-introduction-to-gazebo","label":"Lesson 1 - Introduction to Gazebo","docId":"module-2-the-digital-twin/lesson-1-introduction-to-gazebo","unlisted":false},{"type":"link","href":"/docs/module-2-the-digital-twin/lesson-2-physics-simulation","label":"Lesson 2 - Physics Simulation in Gazebo","docId":"module-2-the-digital-twin/lesson-2-physics-simulation","unlisted":false},{"type":"link","href":"/docs/module-2-the-digital-twin/lesson-3-high-fidelity-rendering","label":"Lesson 3 - High-Fidelity Rendering and Human-Robot Interaction","docId":"module-2-the-digital-twin/lesson-3-high-fidelity-rendering","unlisted":false},{"type":"link","href":"/docs/module-2-the-digital-twin/lesson-4-sensor-simulation","label":"Lesson 4 - Sensor Simulation in Gazebo","docId":"module-2-the-digital-twin/lesson-4-sensor-simulation","unlisted":false}],"collapsed":true,"collapsible":true,"href":"/docs/module-2-the-digital-twin/intro"},{"type":"category","label":"Module 3: The AI-Robot Brain (NVIDIA Isaac™)","items":[{"type":"link","href":"/docs/module-3-the-ai-robot-brain/lesson-1-introduction-to-nvidia-isaac","label":"Lesson 1 - Introduction to NVIDIA Isaac","docId":"module-3-the-ai-robot-brain/lesson-1-introduction-to-nvidia-isaac","unlisted":false},{"type":"link","href":"/docs/module-3-the-ai-robot-brain/lesson-2-photorealistic-simulation","label":"Lesson 2 - Isaac Sim for Photorealistic Simulation","docId":"module-3-the-ai-robot-brain/lesson-2-photorealistic-simulation","unlisted":false},{"type":"link","href":"/docs/module-3-the-ai-robot-brain/lesson-3-hardware-accelerated-vslam","label":"Lesson 3 - Isaac ROS and Hardware-Accelerated VSLAM","docId":"module-3-the-ai-robot-brain/lesson-3-hardware-accelerated-vslam","unlisted":false},{"type":"link","href":"/docs/module-3-the-ai-robot-brain/lesson-4-path-planning-for-bipedal-movement","label":"Lesson 4 - Nav2 for Bipedal Humanoid Navigation","docId":"module-3-the-ai-robot-brain/lesson-4-path-planning-for-bipedal-movement","unlisted":false}],"collapsed":true,"collapsible":true,"href":"/docs/module-3-the-ai-robot-brain/intro"},{"type":"category","label":"Module 4: Vision-Language-Action (VLA)","items":[{"type":"link","href":"/docs/module-4-vision-language-action/lesson-1-introduction-to-vla","label":"Lesson 1 - Introduction to Vision-Language-Action Systems","docId":"module-4-vision-language-action/lesson-1-introduction-to-vla","unlisted":false},{"type":"link","href":"/docs/module-4-vision-language-action/lesson-2-voice-to-action-whisper","label":"Lesson 2 - Voice-to-Action with OpenAI Whisper","docId":"module-4-vision-language-action/lesson-2-voice-to-action-whisper","unlisted":false},{"type":"link","href":"/docs/module-4-vision-language-action/lesson-3-cognitive-planning-llms","label":"Lesson 3 - Cognitive Planning with LLMs","docId":"module-4-vision-language-action/lesson-3-cognitive-planning-llms","unlisted":false},{"type":"link","href":"/docs/module-4-vision-language-action/lesson-4-capstone-project","label":"Lesson 4 - Capstone Project - The Autonomous Humanoid","docId":"module-4-vision-language-action/lesson-4-capstone-project","unlisted":false}],"collapsed":true,"collapsible":true,"href":"/docs/module-4-vision-language-action/intro"}]},"docs":{"getting-started":{"id":"getting-started","title":"Getting Started","description":"How to begin your journey with Physical AI & Humanoid Robotics","sidebar":"tutorialSidebar"},"intro":{"id":"intro","title":"Introduction to Physical AI & Humanoid Robotics","description":"An overview of the Physical AI & Humanoid Robotics book","sidebar":"tutorialSidebar"},"module-1-the-robotic-nervous-system/intro":{"id":"module-1-the-robotic-nervous-system/intro","title":"Introduction to Module 1 - The Robotic Nervous System (ROS 2)","description":"Middleware for robot control, covering ROS 2 fundamentals","sidebar":"tutorialSidebar"},"module-1-the-robotic-nervous-system/lesson-1-introduction-to-ros2":{"id":"module-1-the-robotic-nervous-system/lesson-1-introduction-to-ros2","title":"Lesson 1 - Introduction to ROS 2","description":"Understanding the middleware architecture of ROS 2 for robot control","sidebar":"tutorialSidebar"},"module-1-the-robotic-nervous-system/lesson-2-nodes-topics-services":{"id":"module-1-the-robotic-nervous-system/lesson-2-nodes-topics-services","title":"Lesson 2 - ROS 2 Nodes, Topics, and Services","description":"Understanding the communication patterns in ROS 2","sidebar":"tutorialSidebar"},"module-1-the-robotic-nervous-system/lesson-3-bridging-python-agents":{"id":"module-1-the-robotic-nervous-system/lesson-3-bridging-python-agents","title":"Lesson 3 - Bridging Python Agents to ROS Controllers using rclpy","description":"Connecting AI agents implemented in Python to ROS controllers","sidebar":"tutorialSidebar"},"module-1-the-robotic-nervous-system/lesson-4-understanding-urdf":{"id":"module-1-the-robotic-nervous-system/lesson-4-understanding-urdf","title":"Lesson 4 - Understanding URDF (Unified Robot Description Format) for Humanoids","description":"Describing robot structure, kinematics, and dynamics using URDF","sidebar":"tutorialSidebar"},"module-2-the-digital-twin/intro":{"id":"module-2-the-digital-twin/intro","title":"Introduction to Module 2 - The Digital Twin (Gazebo & Unity)","description":"Physics simulation and environment building for humanoid robotics","sidebar":"tutorialSidebar"},"module-2-the-digital-twin/lesson-1-introduction-to-gazebo":{"id":"module-2-the-digital-twin/lesson-1-introduction-to-gazebo","title":"Lesson 1 - Introduction to Gazebo","description":"Setting up simulation environments for humanoid robotics","sidebar":"tutorialSidebar"},"module-2-the-digital-twin/lesson-2-physics-simulation":{"id":"module-2-the-digital-twin/lesson-2-physics-simulation","title":"Lesson 2 - Physics Simulation in Gazebo","description":"Modeling gravity, collisions, and physical interactions in simulation","sidebar":"tutorialSidebar"},"module-2-the-digital-twin/lesson-3-high-fidelity-rendering":{"id":"module-2-the-digital-twin/lesson-3-high-fidelity-rendering","title":"Lesson 3 - High-Fidelity Rendering and Human-Robot Interaction","description":"Visual rendering and human-robot interaction in simulation","sidebar":"tutorialSidebar"},"module-2-the-digital-twin/lesson-4-sensor-simulation":{"id":"module-2-the-digital-twin/lesson-4-sensor-simulation","title":"Lesson 4 - Sensor Simulation in Gazebo","description":"Simulating realistic sensor data including LiDAR, depth cameras, and IMUs","sidebar":"tutorialSidebar"},"module-3-the-ai-robot-brain/intro":{"id":"module-3-the-ai-robot-brain/intro","title":"Introduction to Module 3 - The AI-Robot Brain (NVIDIA Isaac™)","description":"Advanced perception and training using NVIDIA Isaac for humanoid robotics","sidebar":"tutorialSidebar"},"module-3-the-ai-robot-brain/lesson-1-introduction-to-nvidia-isaac":{"id":"module-3-the-ai-robot-brain/lesson-1-introduction-to-nvidia-isaac","title":"Lesson 1 - Introduction to NVIDIA Isaac","description":"Overview of the NVIDIA Isaac platform and ecosystem for robotics","sidebar":"tutorialSidebar"},"module-3-the-ai-robot-brain/lesson-2-photorealistic-simulation":{"id":"module-3-the-ai-robot-brain/lesson-2-photorealistic-simulation","title":"Lesson 2 - Isaac Sim for Photorealistic Simulation","description":"Using Isaac Sim for synthetic data generation and perception training","sidebar":"tutorialSidebar"},"module-3-the-ai-robot-brain/lesson-3-hardware-accelerated-vslam":{"id":"module-3-the-ai-robot-brain/lesson-3-hardware-accelerated-vslam","title":"Lesson 3 - Isaac ROS and Hardware-Accelerated VSLAM","description":"Leveraging GPU acceleration for visual SLAM and navigation in humanoid robots","sidebar":"tutorialSidebar"},"module-3-the-ai-robot-brain/lesson-4-path-planning-for-bipedal-movement":{"id":"module-3-the-ai-robot-brain/lesson-4-path-planning-for-bipedal-movement","title":"Lesson 4 - Nav2 for Bipedal Humanoid Navigation","description":"Path planning and navigation for bipedal humanoid robots using Nav2","sidebar":"tutorialSidebar"},"module-4-vision-language-action/capstone_implementation":{"id":"module-4-vision-language-action/capstone_implementation","title":"Capstone Project Implementation Guide","description":"Autonomous Humanoid: Voice Command to Action"},"module-4-vision-language-action/intro":{"id":"module-4-vision-language-action/intro","title":"Introduction to Module 4 - Vision-Language-Action (VLA)","description":"The convergence of LLMs and Robotics for humanoid systems","sidebar":"tutorialSidebar"},"module-4-vision-language-action/lesson-1-introduction-to-vla":{"id":"module-4-vision-language-action/lesson-1-introduction-to-vla","title":"Lesson 1 - Introduction to Vision-Language-Action Systems","description":"Understanding the convergence of vision, language, and action in robotics","sidebar":"tutorialSidebar"},"module-4-vision-language-action/lesson-2-voice-to-action-whisper":{"id":"module-4-vision-language-action/lesson-2-voice-to-action-whisper","title":"Lesson 2 - Voice-to-Action with OpenAI Whisper","description":"Using OpenAI Whisper for voice command processing in humanoid robots","sidebar":"tutorialSidebar"},"module-4-vision-language-action/lesson-3-cognitive-planning-llms":{"id":"module-4-vision-language-action/lesson-3-cognitive-planning-llms","title":"Lesson 3 - Cognitive Planning with LLMs","description":"Using Large Language Models to translate natural language into robotic actions","sidebar":"tutorialSidebar"},"module-4-vision-language-action/lesson-4-capstone-project":{"id":"module-4-vision-language-action/lesson-4-capstone-project","title":"Lesson 4 - Capstone Project - The Autonomous Humanoid","description":"Implementing a complete autonomous humanoid system that responds to voice commands","sidebar":"tutorialSidebar"},"tutorial-basics/congratulations":{"id":"tutorial-basics/congratulations","title":"Congratulations!","description":"You have just learned the basics of Docusaurus and made some changes to the initial template."},"tutorial-basics/create-a-blog-post":{"id":"tutorial-basics/create-a-blog-post","title":"Create a Blog Post","description":"Docusaurus creates a page for each blog post, but also a blog index page, a tag system, an RSS feed..."},"tutorial-basics/create-a-document":{"id":"tutorial-basics/create-a-document","title":"Create a Document","description":"Documents are groups of pages connected through:"},"tutorial-basics/create-a-page":{"id":"tutorial-basics/create-a-page","title":"Create a Page","description":"Add Markdown or React files to src/pages to create a standalone page:"},"tutorial-basics/deploy-your-site":{"id":"tutorial-basics/deploy-your-site","title":"Deploy your site","description":"Docusaurus is a static-site-generator (also called Jamstack)."},"tutorial-basics/markdown-features":{"id":"tutorial-basics/markdown-features","title":"Markdown Features","description":"Docusaurus supports Markdown and a few additional features."},"tutorial-extras/manage-docs-versions":{"id":"tutorial-extras/manage-docs-versions","title":"Manage Docs Versions","description":"Docusaurus can manage multiple versions of your docs."},"tutorial-extras/translate-your-site":{"id":"tutorial-extras/translate-your-site","title":"Translate your site","description":"Let's translate docs/intro.md to French."}}}}